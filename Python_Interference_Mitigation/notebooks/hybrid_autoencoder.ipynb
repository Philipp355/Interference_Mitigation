{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from src.models.hybrid_autoencoder import RadarHybridAutoencoder\n",
    "from src.data.dataset import RadarDataset\n",
    "from src.utils.training_validation import train_autoencoder, process_and_save_results\n",
    "from src.utils.evaluation import evaluate_reconstruction\n",
    "from src.models.model_utils import get_model_info\n",
    "import mat73\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and Prepare Data\n",
    "# Load training data\n",
    "data_path = '../data/raw/dataset_2t1.mat'\n",
    "data = mat73.loadmat(data_path)\n",
    "radar_cube = data['radar_cube']\n",
    "clean_data = data['clean_signals']\n",
    "\n",
    "print(f\"Radar cube shape: {radar_cube.shape}\")\n",
    "print(f\"Clean data shape: {clean_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare DataLoader\n",
    "# Create dataset and split\n",
    "full_dataset = RadarDataset(radar_cube, clean_data)\n",
    "val_size = int(len(full_dataset) * 0.2)\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 4   # small batch size considering cpu memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize and Analyze Model\n",
    "model = RadarHybridAutoencoder()\n",
    "model_info = get_model_info(model)\n",
    "print(\"\\nModel Architecture Information:\")\n",
    "print(f\"Model Type: {model_info['model_type']}\")\n",
    "print(f\"Total Parameters: {model_info['total_params']:,}\")\n",
    "print(f\"Trainable Parameters: {model_info['trainable_params']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train Model\n",
    "trained_model, history, memory_usage, training_time = train_autoencoder(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate Model\n",
    "# Evaluate on validation set\n",
    "metrics = evaluate_reconstruction(trained_model, radar_cube, clean_data, frame_idx=0)\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"MSE: {metrics['mse']:.2e}\")\n",
    "print(f\"PSNR: {metrics['psnr']:.2f} dB\")\n",
    "print(f\"SIR Improvement: {metrics['sir_improvement']:.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
